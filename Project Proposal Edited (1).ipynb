{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a003d3",
   "metadata": {},
   "source": [
    "# Project Proposal Form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec67b63",
   "metadata": {},
   "source": [
    "## Project Title : The Analysis of Eartquakes in Turkey Between 1910 - 2017\n",
    "### Team Members: \n",
    "Mercan Uz 090190320 <br> \n",
    "Beyza Çelik 090190362"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcc3ef",
   "metadata": {},
   "source": [
    "### Project Proposal\n",
    "\n",
    "Especially when we are living in the Istanbul and waiting for a very big earthquake, this project can be really helpful for minimizing the loss of lives. Besides the expected big Istanbul earthquake, it can be used in life choices, investments and more. We can evaluate the probability of earthquake and shape our investments by the lowest loss risk. The risk of eartquakes is an important investment condition for invertors. Investors can safely invest to towns where the earthquake risk is low and it can be helpful for them to planning their capital in the long run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1569c",
   "metadata": {},
   "source": [
    "In this project, our goal is aswering the following questions:\n",
    "   * Can we estimate the magnitude, time and location of future earthquakes by using previous earthquake data ~~for each city of Turkey~~?\n",
    "   * Can we say earthquakes are triggering each other (i.e. can an earthquake in ~~İzmir~~ Bursa trigger one in Istanbul).\n",
    "   * Can we find a relation between the types and provinces of earthquakes in Turkey?\n",
    "   * What are the most and least risky ~~cities~~ subprovinces according to earthquake risk by estimated probabilities?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f43da",
   "metadata": {},
   "source": [
    "In short, for accomplishing these goals, we will analyze the data according the type, location, magnitude etc. and we will search for any relation in the data. We will analyze and visualize when it is necessary, we are dealing with a kind of big data and it is not easy that analyzing so many rows by human eyes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae2679",
   "metadata": {},
   "source": [
    "### Project Data:\n",
    "We will use the following data in our project: [B.Ü. KRDAE Bölgesel Deprem-Tsunami İzleme ve Değerlendirme Merkezi](http://www.koeri.boun.edu.tr/sismo/2/deprem-verileri/sayisal-veriler/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76bdb0",
   "metadata": {},
   "source": [
    "In this project, we will use the data from directly Boğaziçi University. \n",
    "<br>Our first claim about the data was;\n",
    "* The data covers up all the recorded earthquakes in the latitudes between 35 - 42; longitudes 26 - 45. The database search time filter was set to dates 01/01/2017 to 30/12/2022. As there are too many earthquakes which have intensities smaller than 4.0, the filter of intensity was set to 3.5 to 9.0 (there was no earthquakes recorded larger than 9.0 intensity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ef1c6",
   "metadata": {},
   "source": [
    "Then, we noticed after we get FTP key from Boğaziçi University, there are really big data, like hundereds of gigabytes. So, we made a decision about filtering our data. We will especillay look for Istanbul and the circle around the Istanbul with 50kms diameter because of the expecting big Istanbul earthquake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5eb406",
   "metadata": {},
   "source": [
    "![Istanbul](./data/data_circle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd317f4",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "We are planning to use following libraries; scikit, matplotlib, seaborn, numpy, pandas. Because of project has not done yet, we may add some libraries in the process. Our algorithm will be looking for the eartquakes in the 3 days of a random selected earthquakes happened, will compare depth and magnitutes will be look for a relationship between them such as logarithmic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd05ce7",
   "metadata": {},
   "source": [
    "We will check our hypothesis in the process of project and then, we will be able to answer or verify our hypothesis, we will definitely mention this in the final form. For now, our hypothesis is earthquakes with short distance and big magnitudes can trigger the others, you can think this as aftershockes. More detailed, we are planning to explain the relationship between earthquakes and its aftershockes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f985f08",
   "metadata": {},
   "source": [
    "We will make predictions for the past and look for are they actually happened. Then, we will calculate the correctness of our algorithm and hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2636f",
   "metadata": {},
   "source": [
    "### Task Distribution\n",
    "Beyza Çelik, within the scope of the project, to create a graph showing the earthquake frequencies for each of the districts in the red region on the map above, and to classify earthquakes according to the Richter scale on this graph and to establish the relationship between them on a district basis as a result of this classification. Another topic is to find the most risky and least risky districts by not calculating the frequency of earthquakes that took place between 2017-2022 for the districts studied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673ccf1",
   "metadata": {},
   "source": [
    "Mercan Uz will import the data from the source which we have mentioned above, clear and filter the data. Makes the maps according to coordinates of earthquakes for visualisation and displays them according to their magnitudes. Will analyze the previous earthquakes data and search for a mathematical (scientific) relationship between them for verifying that an earthquake triggers earthquakes. Decide about which probability method will be the best for this comparisons. Will make assumptions for earthquakes in the past and calculate the probability of correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80edf8cc",
   "metadata": {},
   "source": [
    "At the end, we will compare our results and decide about the verifying or declining the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612b1fc",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae97f11",
   "metadata": {},
   "source": [
    "# Atabey's notes\n",
    "\n",
    "## Round 1\n",
    "\n",
    "I really like the dataset, but it is not the most recent one. Bogazici University has the most recent data on their [B.Ü. KRDAE Bölgesel Deprem-Tsunami İzleme ve Değerlendirme Merkezi](http://www.koeri.boun.edu.tr/sismo/2/deprem-verileri/sayisal-veriler/). Get the data from 2017 until now from there.\n",
    "\n",
    "Also, even though I like the dataset and questions you asked the details on how you are going to answer those questions is not clear. You must state your hypothesis (past earthquakes give us clues on earthquakes in the near future) and questions (such as \"Can we say earthquakes are triggering each other (i.e. can an earthquake in Izmir trigger one in Istanbul)?\"), what type of machine learning algorithms are there to test your hyoptheses and answer your questions? How are they going to help you to answer the questions? Are the experiments you did verify your hypothesis? How? How are you going to know if the results of your experiments confirm and fail to confirm you hypothesis? I am going to see a detailed methodology section on these points.\n",
    "\n",
    "Finally, I am going to need a detailed calendar: who is going to do what and when?\n",
    "\n",
    "## Round 2\n",
    "\n",
    "You haven't addressed the questions I raised earlier, or made any of the changes I asked."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
